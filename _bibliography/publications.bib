---
---
References
==========


@InProceedings{pmlr-v202-shin23c,
  title = 	 {Improved Learning-Augmented Algorithms for the Multi-Option Ski Rental Problem via Best-Possible Competitive Analysis},
  author =       {Shin, Yongho and Lee, Changyeol and Lee, Gukryeol and An, Hyung-Chan},
  booktitle = 	 {<b>Proceedings of the 40th International Conference on Machine Learning (ICML)</b>},
  pages = 	 {31539--31561},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month =7,
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/shin23c/shin23c.pdf},
  url = 	 {https://proceedings.mlr.press/v202/shin23c.html},
  arxiv= {2302.06832},
  poster = {ICML_2023_poster.pdf},
  slides = {WAAC_2024_slides.pdf},
  abstract = 	 {In this paper, we present improved learning-augmented algorithms for the multi-option ski rental problem. Learning-augmented algorithms take ML predictions as an added part of the input and incorporates these predictions in solving the given problem. Due to their unique strength that combines the power of ML predictions with rigorous performance guarantees, they have been extensively studied in the context of online optimization problems. Even though ski rental problems are one of the canonical problems in the field of online optimization, only deterministic algorithms were previously known for multi-option ski rental, with or without learning augmentation. We present the first randomized learning-augmented algorithm for this problem, surpassing previous performance guarantees given by deterministic algorithms. Our learning-augmented algorithm is based on a new, provably best-possible randomized competitive algorithm for the problem. Our results are further complemented by lower bounds for deterministic and randomized algorithms, and computational experiments evaluating our algorithms’ performance improvements.}
}

@article{shin2023optimal,
  title={On Optimal Consistency-Robustness Trade-Off for Learning-Augmented Multi-Option Ski Rental},
  author={Shin, Yongho and Lee, Changyeol and An, Hyung-Chan},
  journal={See the journal paper by Shin, Lee, Lee, and An (TALG'25) (arXiv preprint : arXiv:2312.02547)},
  arxiv= {2312.02547},
  year={2023},
  month=12,
  abstract = {The learning-augmented multi-option ski rental problem generalizes the classical ski rental problem in two ways: the algorithm is provided with a prediction on the number of days we can ski, and the ski rental options now come with a variety of rental periods and prices to choose from, unlike the classical two-option setting. Subsequent to the initial study of the multi-option ski rental problem (without learning augmentation) due to Zhang, Poon, and Xu, significant progress has been made for this problem recently in particular. The problem is very well understood when we relinquish one of the two generalizations -- for the learning-augmented classical ski rental problem, algorithms giving best-possible trade-off between consistency and robustness exist; for the multi-option ski rental problem without learning augmentation, deterministic/randomized algorithms giving the best-possible competitiveness have been found. However, in presence of both generalizations, there remained a huge gap between the algorithmic and impossibility results. In fact, for randomized algorithms, we did not have any nontrivial lower bounds on the consistency-robustness trade-off before. This paper bridges this gap for both deterministic and randomized algorithms. For deterministic algorithms, we present a best-possible algorithm that completely matches the known lower bound. For randomized algorithms, we show the first nontrivial lower bound on the consistency-robustness trade-off, and also present an improved randomized algorithm. Our algorithm matches our lower bound on robustness within a factor of e/2 when the consistency is at most 1.086.}
}

@article{an2025handling,
  title={Handling LP-Rounding for Hierarchical Clustering and Fitting Distances by Ultrametrics},
  author={An, Hyung-Chan and Kao, Mong-Jen and Lee, Changyeol and Lee, Mu-Ting},
  journal={<b>(To appear at FOCS 2025)</b> arXiv preprint arXiv:2504.06700},
  year={2025},
  month=4,
  arxiv={2504.06700},
  abstract ={We consider the classic correlation clustering problem in the hierarchical setting. Given a complete graph G=(V,E) and ℓ layers of input information, where the input of each layer consists of a nonnegative weight and a labeling of the edges with either + or -, this problem seeks to compute for each layer a partition of V such that the partition for any non-top layer subdivides the partition in the upper-layer and the weighted number of disagreements over the layers is minimized.
Hierarchical correlation clustering is a natural formulation of the classic problem of fitting distances by ultrametrics, which is further known as numerical taxonomy in the literature. While single-layer correlation clustering received wide attention since it was introduced and major progress evolved in the past three years, few is known for this problem in the hierarchical setting. The lack of understanding and adequate tools is reflected in the large approximation ratio known for this problem originating from 2021.
In this work we make both conceptual and technical contributions towards the hierarchical clustering problem. We present a simple paradigm that greatly facilitates LP-rounding in hierarchical clustering, illustrated with an algorithm providing a significantly improved approximation guarantee of 25.7846 for the hierarchical correlation clustering problem. Our techniques reveal surprising new properties of the formulation presented and subsequently used in previous works for hierarchical clustering over the past two decades. This provides an interpretation on the core problem in hierarchical clustering as the problem of finding cuts with prescribed properties regarding average distances.
We further illustrate this perspective by showing that a direct application of the techniques gives a simple alternative to the state-of-the-art result for the ultrametric violation distance problem.}
}

@inproceedings{lee2025improved,
  title={Improved Algorithms for Overlapping and Robust Clustering of Edge-Colored Hypergraphs: An {LP}-Based Combinatorial Approach},
  author={Changyeol Lee and Yongho Shin and Hyung-Chan An},
  booktitle={<b>The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS)</b>},
  year={2025},
  month=12,
  url={https://openreview.net/forum?id=F3DrgOZYc6},
  pdf={https://openreview.net/pdf?id=F3DrgOZYc6},
  slides ={NeurIPS_2025_slides.pdf},
  arxiv= {2505.18043},
  abstract = {Clustering is a fundamental task in both machine learning and data mining. Among various methods, edge-colored clustering (ECC) has emerged as a useful approach for handling categorical data. Given a hypergraph with (hyper)edges labeled by colors, ECC aims to assign vertex colors to minimize the number of edges where the vertex color differs from the edge's color. However, traditional ECC has inherent limitations, as it enforces a nonoverlapping and exhaustive clustering. To tackle these limitations, three versions of ECC have been studied: Local ECC and Global ECC, which allow overlapping clusters, and Robust ECC, which accounts for vertex outliers. For these problems, both linear programming (LP) rounding algorithms and greedy combinatorial algorithms have been proposed. While these LP-rounding algorithms provide high-quality solutions, they demand substantial computation time; the greedy algorithms, on the other hand, run very fast but often compromise solution quality. In this paper, we present a family of algorithms that combines the strengths of LP with the computational efficiency of combinatorial algorithms. Both experimental and theoretical analyses show that our algorithms efficiently produce high-quality solutions for all three problems: Local, Global, and Robust ECC. We complement our algorithmic contributions with complexity-theoretic inapproximability results and integrality gap bounds, which suggest that significant theoretical improvements are unlikely. Our results also answer two open questions previously raised in the literature.},
}

@article{shin2025improved,
author = {Shin, Yongho and Lee, Changyeol and Lee, Gukryeol and An, Hyung-Chan},
title = {Improved Learning-Augmented Algorithms and (Tight) Lower Bounds for Multi-Option Ski Rental Problem},
year = {2025},
issue_date = {January 2026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1549-6325},
url = { https://dl.acm.org/doi/10.1145/3763239?cid=99661021532 },
abstract = {We present improved learning-augmented algorithms for the multi-option ski rental problem. Learning-augmented algorithms take machine learning (ML) predictions as an added part of the input and incorporate these predictions in solving the given problem. Due to their unique strength that combines the power of ML predictions with provable performance guarantees, they have been extensively studied in the context of online optimization problems. While the multi-option ski rental problem provides a natural generalization of the classical rent-or-buy variant, only deterministic algorithms for this problem were previously known, with or without learning augmentation.In this article, we first present that a very simple modification to a previously known algorithm suffices to give an improved deterministic learning-augmented algorithm. In fact, we prove that this algorithm has the best-possible performance of a deterministic algorithm by giving a matching lower bound. Then we present the first randomized learning-augmented algorithm, which surpasses the lower bound of deterministic algorithms; this learning-augmented algorithm is based on a new best-possible randomized competitive algorithm. These results are complemented by lower bounds for randomized competitive/learning-augmented algorithms.},
journal = {<b>ACM Transactions on Algorithms (TALG)</b>},
month = 11,
articleno = {11},
numpages = {30},
keywords = {multi-option ski rental problem, learning-augmented algorithms, online algorithms, lower bounds, consistency-robustness trade-off}
}

@article{abbasi2025chromatic,
  title={Chromatic correlation clustering via cluster {LP}},
  author={Fateme Abbasi and Hyung-Chan An and Jarosław Byrka and Changyeol Lee and Yongho Shin},
  journal={arXiv preprint arXiv:2510.13446},
  year={2025},
  month=10,
  arxiv= {2510.13446},
  abstract = {Correlation Clustering is a fundamental clustering problem, and there has been a line of work on improving the approximation ratio for this problem in recent years. A key algorithmic component in these works is the cluster LP. Chromatic Correlation Clustering is an interesting generalization that has also been intensively studied. In light of success of the cluster LP in Correlation Clustering, it would be an interesting question whether the cluster LP can be used in Chromatic Correlation Clustering. We answer this question with affirmatives by presenting a $(2+\epsilon)$-approximation algorithm for Chromatic Correlation Clustering using a chromatic cluster LP.}
}